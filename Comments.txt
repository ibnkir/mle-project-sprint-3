Комментарии KN после 2-й итерации
08.06.2024

Привет, 
 
по результатам 2-х наших проектов у меня сложилось стойкое впечатление, 
что, к сожалению, ты не очень внимательно читаешь md-файлы и другие приложенные материалы. 
О том же нагрузочном скрипте generate_requests.py у меня сказано
и в readme (описание репозитория), и в инструкции. 
Из-за этого я немного переживаю, что ты можешь снова что-то упустить из моих объяснений ниже,
и мы уйдем на следующий круг.
Давай пжл ценить время друг друга.
Я внимательно читаю твои комментарии и жду от тебя того же.
Также большая просьба более четко и ясно формулировать свои мысли, даже если ты очень торопишься. 
К сожалению, я не понимаю некоторые из твоих комментариев.
Если у тебя мало времени, то просьба очень срочно (!!!) и в рабочем порядке 
передать проверку своим коллегам. 
Для 3-й итерации, если она понадобится, я собственно предлагаю так и сделать,
потому что это too much. 
Я действительно нужны конструктивные комментарии и советы, 
но терять время из-за недопонимания по чужой невнимательности я не хочу, сорри.


Теперь по порядку.

__________________________________________
Итак, что касается пост-запросов на странице /docs 
(по сути я здесь дублирую свою инструкцию, но я думал, что такие детали как бы очевидны). 
После запуска сервиса тем или иным способом 
тебе нужно развернуть зеленую панель POST, нажать Try it out,
и чуть ниже будет поле Requested body,
где уже заполнены все параметры модели по умолчанию. Тебе остается только нажать Execute.
И ниже - в поле Response body - ты увидишь json с ответом. Н-р, такой:
{
  "status": "OK",
  "score": 8494489.99991846
}

Далее ты можешь поменять параметры модели в том же поле Requested body, 
сделать их неправильными, удалить какие-то из них итд итп.
Н-р, если ты поставишь минус у кол-ва этажей, то получишь ответ:
{
  "status": "Error",
  "message": "Some numerical features in model params are negative"
}

А что и куда скопировала ты, я не могу понять в принципе. Ты получила
{"status":"Error","message":"Problem with request, 'str' object has no attribute 'transform'"},
т.к. вместо числовых значений почему-то и как-то смогла вставить строковые. 
Вообще, желательно прикладывать более детальное описание своего эксперимента, 
чтобы его можно было воспроизвести и найти причину. 
Но лучше все-таки пжл попробуй сделать как у меня и вообще как это давалось у нас на спринте. 
Посмотри материалы спринта, сразу отпадет очень много вопросов.
__________________________________________

Комментарий в файле fastapi_app.py:
"Для продуктового кода скрипт в формате "строчка за строчкой" - практика которую давно не используют. 
Код должен быть обернут в методы, классы...
...Все что мы хотим сделать, при прямом запуске скрипта должно прописываться в блоке 
в самом низу скрипта if __name__ == '__main__':
Подробнее: https://realpython.com/if-name-main-python/
"

- Прости, но причем тут main и эта ссылка? Когда мы выполняем команду
uvicorn ml_service.fastapi_app:app --reload --port 1702 --host 0.0.0.0
то это не прямой запуск, здесь main не вызвается. 
Но я обернул приложение в класс, это конструктивный коммент, спасибо. 
А что касается main(), то такой у меня есть например в fastapi_handler.py, 
чтобы протестировать обработчик без вызова unicorn.
__________________________________________

Комментарий в файле fastapi_handler.py:
"..там где bool, было бы хорошо оставить и инт, если пользователь захочет ввести 1 или 0, вместо True/False"

- Добавил. 
__________________________________________

Комментарий в файле fastapi_handler.py: 
"В своей модели которую ты обучал, скорее всего были скейлеры и прочие преобразователи признаков. 
Не увидела что ты тут их используешь. Модель должна получать данные в точно таком же формате, 
на чем она обучалась. Иначе для нее это будут данные которые она никогда не видела..."

- Я использую пайплайн, включающий в себя все трансформеры данных и плюс саму регрессионную модель,
  я упомянул об этом в самом начале readme,
  и файл называется соотвествующим образом: "flats_prices_pipeline.pkl"
  И в ноутбуке это можно увидеть, включая структуру пайплайна, как делать инференс, 
  что подавать на вход итд итп.

  Поэтому мне не надо применять скейлеры и прочие трансформеры,
  я подаю на вход пайплайна данные в том же виде, что и в исходном датасете.
  Единственно, что я делаю явно перед вызовом predict у пайплайна, это считаю возраст здания
  и удаляю год постройки. То же самое я делал и при обучении модели. Там еще я удалял параметр 
  studio, т.к. он был константным. А здесь я проверяю, не передал ли его пользователь.
  И если передал, то выкидываю из словаря еще на этапе валидации запроса.

  P.S. Вообще, я не знаю, если бы я проверял работы, 
  то мне было бы наверное проще сначала глянуть код в ноутбуке, пробежаться по readme
  и понять, что там за модель, чем писать столько текста. Ну, да ладно...
__________________________________________

Комментарий по Этапу 2:
"Запустилось, но запрос выдает ту же ошибку, что логично, т.к. сервис тот же. 
Надо поправить. Кроме того докер почему то не останавливается Ctrl+C, зависает все. 
Приходится из другого терминала стопать по ID. Не знаю почему, может не хватает ресурсов..."

- TODO   
__________________________________________

Комментарии по Этапам 3-4:

"Для того чтобы вывелись данные на дашборд графаны, 
нужно написать скрипт нагрузочный, симулирующий нагрузку, где посылается несколько запросов 
питоновский или шелл. Это есть в задании к этапу 4."

- Файл с нагрузочным скриптом называется generate_requests.py. 
  О нем говроится и в readme, и в инструкции.  
  Для его запуска нужно перейти в папку services (см. инструкцию)


"Ревьюер не должен создавать панели и вручную выражения отправлять. Это тоже нужно поправить."

- TODO


"Кстати я в конце запустила скрипт 
для проверки верных - неверных запросов, все с одной и той же багой падают как в этапе 1 я описала."

- А здесь я вообще ничего не понял. Ты же выше написала, что не нашла 
  мой нагрузочный скрипт, а здесь пишешь, что все-таки что-то запустила. 
  Или о каком скрипте речь? Ты сама написала какой-то свой собственный скрипт? 
  Мой скрипт generate_requests.py не делает "проверку верных - неверных запросов", 
  он просто генерирует корректные и ошибочные запросы. 
  Для корректных запросов он берет данные из исходного датасета.
  При его запуске в терминале выводятся ответы сервиса, и видно, что все работает корректно. 
  Также результаты видны на странице /metrics и в прометеусе.
  В общем, я не понял этот комментарий от начала и до конца, просьба пояснить либо удалить.
  Здесь НЕТ никакой баги.
