## Инструкции по запуску микросервиса

### 0. Подготовка репозитория и модели
- Перейти в домашнюю папку и склонировать репозиторий, после чего перейти в папку проекта:
    ```bash
    cd ~
    git clone https://github.com/ibnkir/mle-project-sprint-3.git
    cd mle-project-sprint-3
    ```
- Загрузить модель по [ссылке](https://disk.yandex.ru/d/Ce6MX9OaWiyOKA) и положить в папку 
`/services/models/` репозитория. Либо создать и обучить модель самостоятельно, выполнив все ячейки в ноутбуке 
`/notebooks/model_preparation.ipynb`. В этом случае понадобятся исходные данные, которые можно загрузить из БД также с помощью данного ноутбука или скачать по [ссылке](https://disk.yandex.ru/d/OIInLdG4dZMVZA) и положить в папку ```services/data```.

### 1. FastAPI микросервис в виртуальном окружение
- Установить необходимые библиотеки в текущем или новом виртуальном окружении, 
выполнив следующие команды из корневой папки репозитория:

    Установка в текущем окружении:<br>
        ```
        pip install -r requirements.txt
        ```

    Установка в новом окружении:<br>
        ```sudo apt-get update```<br>
        ```sudo apt-get install python3.10-venv```<br>
        ```python3 -m venv ./venv```<br>
        ```source venv/bin/activate```<br> 
        ```pip install -r requirements.txt```

- Перейти в папку services/
   ```
   cd services
   ```

- Запустить сервер uvicorn (если порт 8081 уже занят, то заменить его на другой)
   ```
   uvicorn ml_service.fastapi_app:app --reload --port 8081 --host 0.0.0.0
   ```

- В браузере ввести адрес http://127.0.0.1:8081/docs для отправки post-запросов через Swagger UI
(при нажатии на кнопку `Try it` появится готовый тестовый пример с правильными параметрами модели) либо выполнить в терминале команду ```curl 127.0.0.1:8081/``` для отправки простого get-запроса.

### 2. FastAPI микросервис в Docker-контейнере
Контейнеризацию сервиса можно выполнить двумя способами, описанными ниже.
В обоих случаях нужно сначала перейти на терминале в папку `services/`.

- Сборка и запуск без использования Docker Compose:
    ```bash
    docker image build . --file Dockerfile_ml_service --tag proj_sprint3:ml_service
    
    docker container run --name ml_service --publish 4601:8081 --volume=./models:/price_app/models --env-file .env proj_sprint3:ml_service
    ```

- Сборка и запуск с помощью Docker Compose:
    ```
    docker compose up --build
    ```

Чтобы обратиться к запущенному сервису, можно ввести в браузере адрес http://127.0.0.1:4601/docs для отправки post-запросов через Swagger UI (при нажатии на кнопку `Try it` появится готовый тестовый пример с правильными параметрами модели) либо выполнить в терминале команду ```curl 127.0.0.1:4601/``` для отправки простого get-запроса.

По окончании работы нужно остановить контейнер, также можно при необходимости удалить образ.

- Остановка и удаление контейнера в случае запуска без использования Docker Compose:
    ```
    docker stop ml_service
    docker rm ml_service
    ```

- Остановка и удаление контейнера в случае запуска с помощью Docker Compose:
    ```
    docker compose down
    ```

Для удаления образа выполняем следующие команды
- Смотрим ID образа
    ```
    docker images
    ```
- Удаляем образ
    ```
    docker rmi -f <id вашего образа>
    ```

### 3. Запуск сервисов для системы мониторинга

### 4. Построение дашборда для мониторинга