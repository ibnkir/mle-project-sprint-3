## Инструкции по запуску микросервиса

### 0. Подготовка репозитория и модели
- Перейти в домашнюю папку и склонировать репозиторий, после чего перейти в папку проекта
    ```bash
    cd ~
    git clone https://github.com/ibnkir/mle-project-sprint-3.git
    cd mle-project-sprint-3
    ```
- Загрузить модель по [ссылке](https://disk.yandex.ru/d/Ce6MX9OaWiyOKA) и положить в папку 
`/services/models/` репозитория. Либо создать и обучить модель самостоятельно, выполнив все ячейки в ноутбуке 
`/notebooks/model_preparation.ipynb`. В этом случае понадобятся исходные данные, которые можно загрузить из БД также с помощью данного ноутбука или скачать по [ссылке](https://disk.yandex.ru/d/OIInLdG4dZMVZA) и положить в папку ```services/data/```.

### 1. FastAPI-микросервис в виртуальном окружении
- Установить необходимые библиотеки в текущем или новом виртуальном окружении, 
выполнив следующие команды из корневой папки репозитория:

    Установка в текущем окружении<br>
        ```
        pip install -r requirements.txt
        ```

    Установка в новом окружении<br>
        ```sudo apt-get update```<br>
        ```sudo apt-get install python3.10-venv```<br>
        ```python3 -m venv ./venv```<br>
        ```source venv/bin/activate```<br> 
        ```pip install -r requirements.txt```

- Перейти в папку с сервисами
   ```
   cd services
   ```

- Запустить сервер uvicorn (если порт 1702 уже занят, то заменить его на другой)
   ```
   uvicorn ml_service.fastapi_app:app --reload --port 1702 --host 0.0.0.0
   ```

- В браузере ввести адрес http://127.0.0.1:1702/docs для отправки post-запросов через Swagger UI
(при нажатии на кнопку `Try it out` появится готовый тестовый пример с правильными параметрами модели) либо выполнить в терминале команду ```curl 127.0.0.1:1702/``` для отправки простого get-запроса.

### 2. FastAPI-микросервис в Docker-контейнере
Контейнеризацию сервиса можно выполнить двумя способами, описанными ниже.
В обоих случаях нужно сначала перейти на терминале в папку `services/`.

- Сборка и запуск контейнера без использования Docker Compose
    ```bash
    docker image build . --file Dockerfile_ml_service --tag proj_sprint3:ml_service
    
    docker container run --name ml_service --publish 4601:1702 --volume=./models:/price_app/models --env-file .env proj_sprint3:ml_service
    ```

- Сборка и запуск контейнера с помощью Docker Compose
    ```
    docker compose up --build
    ```

Чтобы обратиться к запущенному сервису, можно ввести в браузере адрес http://127.0.0.1:4601/docs для отправки post-запросов через Swagger UI (при нажатии на кнопку `Try it out` появится готовый тестовый пример с правильными параметрами модели) либо выполнить в терминале команду ```curl 127.0.0.1:4601/``` для отправки простого get-запроса.

По окончании работы нужно остановить контейнер, также при необходимости можно удалить его образ.

- Остановка и удаление контейнера в случае запуска без использования Docker Compose
    ```
    docker stop ml_service
    docker rm ml_service
    ```

- Остановка и удаление контейнера в случае запуска с помощью Docker Compose
    ```
    docker compose down
    ```

Для удаления образа выполняем следующие команды:
- Смотрим ID образа
    ```
    docker images
    ```
- Удаляем образ по найденному ID
    ```
    docker rmi -f <id вашего образа>
    ```

### 3. Запуск сервисов для системы мониторинга
Для сборки и запуска контейнеров cо всеми сервисами выполнить команду в терминале,
находясь в папке `services/`<br>
    ```
    docker compose up --build
    ```

После выполнения этой команды может возникнуть необходимость вручную удалить и снова добавить порт 9090 сервиса Prometheus на вкладке перенаправления портов.

Проверить работу всех запущенных сервисов можно, перейдя по ссылкам:
- Основной микросервис предсказаний: http://localhost:1702/docs
- Собираемые метрики: http://localhost:9090/metrics
- Целевые сервисы сборщика: http://localhost:9090/targets
- UI для выполнения PromQL-запросов: http://localhost:9090
- Сервис Grafana: http://localhost:3000<br>
Логин и пароль для входа в Grafana должны быть прописаны в файле .env как переменные с именами 
GRAFANA_USER и GRAFANA_PASS соответственно.


### 4. Построение дашборда для мониторинга